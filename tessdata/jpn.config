# Important configurations for CJK mode

# New Segmentation search params
enable_new_segsearch            1
language_model_ngram_on         1
load_fixed_length_dawgs         F
segsearch_max_char_wh_ratio     1.3
language_model_ngram_space_delimited_language F
language_model_ngram_scale_factor 0.1
language_model_use_sigmoidal_certainty T
language_model_ngram_nonmatch_score -20

# always force word_associator to run, whereas "enable_assoc" is conditioned on
# permuter rejection, which may not be what we want until we finalize the
# dictionary issue for CJK
#force_word_assoc   T

# Japanese symbols are more complex than Latin.  Adjust the blob filtering
# thresholds so they do not get filtered out as noise or containers.
# Also force word segmentation to reduce the length of blob sequences.
edges_use_new_outline_complexity    T
edges_children_fix                  T
edges_max_children_per_outline     10
edges_max_children_layers           5
edges_children_count_limit       1000
tosp_force_wordbreak_on_punct       F
textord_force_make_prop_words       T
textord_noise_sizelimit             0.1
textord_noise_normratio             6
textord_max_noise_size              7
textord_noise_rejwords              F
textord_no_rejects                  T
textord_tabfind_vertical_horizontal_mix  T
textord_tabfind_vertical_text_ratio  0.1
textord_tabfind_aligned_gap_fraction 0.5
textord_tabvector_vertical_box_ratio  0.3
textord_tabvector_vertical_gap_fraction  1.5

# Make use of the fact that Japanese can be monospaced, and incorporate that
# into character segmentation cost for search, and inject this cost to
# word rating.
bestrate_pruning_factor             2.0
classify_integer_matcher_multiplier 10
#classify_class_pruner_multiplier    15
assume_fixed_pitch_char_segment     T
use_new_state_cost                  T
segment_segcost_rating              T
heuristic_segcost_rating_base       1.25
heuristic_weight_rating             1
heuristic_weight_width              0.01
heuristic_weight_seamcut            0.001
heuristic_max_char_wh_ratio         1.3
chop_enable                         F
tessedit_char_blacklist             °
segment_nonalphabetic_script        1

# Since we do not have a dictionary for Japanese yet, none of the results
# will be found in DAWG.  We need to relax the stopping condition and turn
# off dictionary based penalties.  Instead, we get additional constraints
# from script consistency.
stopper_nondict_certainty_base   -2
segment_penalty_dict_nonword      1.0
segment_penalty_garbage           1.0
permute_script_word               F
segment_reward_script             0.95
permute_chartype_word             T
segment_reward_chartype           0.96
permute_fixed_length_dawg         T

# Force use of a single x-height mode when the text is written horizontally.
# This information could come from the unicharset (script_has_xheight), but
# it is better in the config file so as to be available when training.
textord_single_height_mode        T

# Use character height as x-height, and estimate it from character pitch and
# kerning width.
textord_use_cjk_fp_model T


# Settings for Japanese as recommended by 服部慎 at:
# https://groups.google.com/forum/#!msg/tesseract-ocr/A4IQlslY7hc/d4xK1PoihfMJ
chop_enable                         T
use_new_state_cost                  F
segment_segcost_rating              F
enable_new_segsearch                0
language_model_ngram_on             0
textord_force_make_prop_words       F